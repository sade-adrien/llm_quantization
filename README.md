# Purpose
This repository gathers work around different llm quantization methods.
Study include the following framework: LLM.int8() (HF), QLoRA (HF), Quanto (HF), llama.cpp (via python bindings), AutoGPTQ (HF), AutoGPTQ (pure)
Yet to be studied: AutoAWQ

See Benchmark.md for quantitative experiments.
For additional notes, see https://docs.google.com/document/d/1pvBRsOkU0ml733xnc_1iEsry7HwysyeDImyY3ZAsZQY/edit?usp=sharing 
