# Purpose
This repository gathers work around different llm quantization methods.
Study include the following framework: LLM.int8() (HF), QLoRA (HF), Quanto (HF), llama.cpp (via python bindings), AutoGPTQ (HF), AutoGPTQ (pure)
Yet to be studied: AutoAWQ

See Benchmark.md for quantitative experiments.
